{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34ecc396-be15-4ccc-b9e6-4abe534f0082",
   "metadata": {},
   "source": [
    "# Limpieza de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6767295b-cf34-4dd9-aeab-83da5510154e",
   "metadata": {},
   "source": [
    "En este notebook vamos a crear 2 funcciones de limpieza de datos, una para el dataframe de ventas y otra para el dataframe de productos. El proceso consiste en: identificar y corregir errores(errores de entrada, como errores tipográficos o de formato), inconsistencias y redundancias en conjuntos de datos, manejar los valores faltantes, manejar los duplicados, eliminar valores que no aportan informacion, cambiar los tipos de variables, crear nuevas columnas basadas en las existentes o para asignar categorías a los datos existentes. Un conjunto de datos limpio y preciso mejora la confiabilidad de los resultados y contribuye a la toma de decisiones informada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0fcb75-7755-43c7-aabc-f13e8c1a727f",
   "metadata": {},
   "source": [
    "IMPORTAMOS LAS LIBRERIAS QUE NECESITAMOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c890281-4991-4034-99a7-2870f4a736f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce402d9d-e569-46a4-b474-5ab271e4bd4a",
   "metadata": {},
   "source": [
    "LEEMOS LOS CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5608dcad-19e9-4c55-82e3-022646be3791",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heuni\\AppData\\Local\\Temp\\ipykernel_7008\\2973436202.py:1: DtypeWarning: Columns (7,9,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('data_ventas.csv')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data_ventas.csv')\n",
    "productos = pd.read_csv('Productosf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eff2ba-b5b8-4fae-b388-03b162b1e00a",
   "metadata": {},
   "source": [
    "## Limpieza de DataFrame Ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79f7e568-ad8e-4099-9e2e-002d0780cd44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def limpieza(data):\n",
    "    #RELLENAMOS NAN\n",
    "    data['CANAL_VENTA']=data['CANAL_VENTA'].fillna('')\n",
    "    data['NOMBRE_PRODUCTO']=data['NOMBRE_PRODUCTO'].fillna('')\n",
    "    data['CADUCIDAD_2']=data['CADUCIDAD_2'].fillna(' ')\n",
    "    data['FECHA_COMPRA']=data['FECHA_COMPRA'].fillna(' ')\n",
    "    data['ID_PRODUCTO'] = data.groupby('NOMBRE_PRODUCTO')['ID_PRODUCTO'].fillna(method='ffill')\n",
    "    \n",
    "    #QUITAMOS LOS DATOS QUE NO NECESITAMOS(las filas donde tenemos: bolsas, palets, descuento, insumo de cafeteria o filas con valores faltantes, las columnas que no nos aportan ninguna informacion valiosa)\n",
    "    data = data[~ data['NOMBRE_PRODUCTO'].str.contains('Bolsa de plastico')]\n",
    "    data = data[~ data['NOMBRE_PRODUCTO'].str.contains('Palets')]\n",
    "    data = data[~ data['NOMBRE_PRODUCTO'].str.contains('DESCUENTO')]\n",
    "    data = data[~ data['NOMBRE_PRODUCTO'].str.contains('AJUSTE A TICKETS')]\n",
    "    data = data[~ data['NOMBRE_PRODUCTO'].str.contains('Insumo de cafeteria')]\n",
    "    data = data[data['ID_PRODUCTO'] != '2']\n",
    "    data = data[data['ID_PRODUCTO'] != '3']\n",
    "    data.drop(data.tail(1).index, inplace=True)\n",
    "    data.drop(['A', 'CADUCIDAD', 'D', 'E'], axis = 1 , inplace=True)\n",
    "    \n",
    "    #TRANSFORMAMOS LAS COLUMNAS FECHA_COMPRA Y CADUCIDAD EN FORMATO DATETIME\n",
    "    data['FECHA_COMPRA'] = pd.to_datetime(data['FECHA_COMPRA'], format = ' %d/%m/%Y', errors='coerce')\n",
    "    data['CADUCIDAD_2'] = pd.to_datetime(data['CADUCIDAD_2'], format = '%m/%d/%Y', errors='coerce')\n",
    "    \n",
    "    #LLENAMOS LAS FILAS DONDE LA FECHA DE CADUCIDAD ES EL AÑO 1970 CON LA ULTIMA FECHA DE CADUCIDAD DE ESTE PRODUCTO\n",
    "    productos_con_error = data[data['CADUCIDAD_2'].dt.year == 1970]\n",
    "    if not productos_con_error.empty:\n",
    "        ultima_fecha_por_producto = data.groupby('ID_PRODUCTO')['CADUCIDAD_2'].max().reset_index()\n",
    "\n",
    "        for index, row in productos_con_error.iterrows():\n",
    "            producto_id = row['ID_PRODUCTO']\n",
    "            nuevas_fechas_caducidad = ultima_fecha_por_producto.loc[ultima_fecha_por_producto['ID_PRODUCTO'] == producto_id, 'CADUCIDAD_2']\n",
    "        \n",
    "            if not nuevas_fechas_caducidad.empty:\n",
    "                nueva_fecha_caducidad = nuevas_fechas_caducidad.values[0]\n",
    "                data.at[index, 'CADUCIDAD_2'] = nueva_fecha_caducidad\n",
    "    \n",
    "    #CREAMOS INDICES PARA LOS CLIENTES \n",
    "    data['INDEX_CLIENTES'] = (data['ID_PRODUCTO'].str.contains('Código:') | data['ID_PRODUCTO'].str.startswith('Código:')).cumsum()\n",
    "    data.drop(data[data['ID_PRODUCTO'] == 'Código:'].index, inplace=True)\n",
    "    \n",
    "    #CREAMOS ETIQUETAS POR CANAL DE VENTA (TENEMOS 3 CANALES)\n",
    "    def asignar_index(canal):\n",
    "        if canal.startswith('TB'):\n",
    "            return 1 #Ventas tienda\"\n",
    "        elif canal.startswith('E'):\n",
    "            return 2 #Ventas Online\"\n",
    "        elif canal.startswith(('SR', 'S9', 'VA', 'C2','R')) or canal.isdigit():\n",
    "            return 3 #Ventas Almacen\"\n",
    "        else:\n",
    "            return 0  # Otro caso   \n",
    "    data['ETIQUETA_CANAL'] = data['CANAL_VENTA'].apply(asignar_index)\n",
    "    \n",
    "    #CAMBIAMOS COLUMNAS CATEGORICAS A NUMERICAS\n",
    "    columnas_numericas = ['CANTIDAD', 'PRECIO_UNIDAD', 'PRECIO_TOTAL']\n",
    "    data[columnas_numericas] = data[columnas_numericas].apply(pd.to_numeric, errors= 'coerce')\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    #LIMPIAMOS Y ADAPTAMOS OTROS DATOS FALTANTES QUE HEMOS IDENTIFICADO DURANTE EL TRABAJO\n",
    "    data = data[data['ID_PRODUCTO'] != '00000000']\n",
    "    data['PRECIO_TOTAL'].fillna(data['CANTIDAD'] * data['PRECIO_UNIDAD'], inplace=True)\n",
    "    data['CANTIDAD'].fillna(data['PRECIO_TOTAL'] / data['PRECIO_UNIDAD'], inplace=True)\n",
    "    data.dropna(subset=['CANTIDAD'], inplace=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b10bda5-751f-487a-9598-5b931e12bfc4",
   "metadata": {},
   "source": [
    "## Limpieza de DataFrame de Productos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "725fe5b0-da2b-49af-894e-4d418d9dc523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def limpieza2(data):\n",
    "    #CAMBIAMOS LOS NOMBRES DE LAS COLUMNAS\n",
    "    data = data.rename(columns={\"Artículo\": \"ID_PRODUCTO\", \"Concepto/Descripción\": \"NOMBRE_PRODUCTO\", \"Familia\": \"CATEGORIA\", \"Subfamilia\": \"PROVEEDOR\", \"Unid. Vendidas\": \"UNIDADES_VENDIDAS\"})\n",
    "    \n",
    "    #RELLENAMOS LOS NAN\n",
    "    data['NOMBRE_PRODUCTO']=data['NOMBRE_PRODUCTO'].fillna('')\n",
    "    \n",
    "    #QUITAMOS LOS DATOS QUE NO NECESITAMOS\n",
    "    data = data[~ data['NOMBRE_PRODUCTO'].str.contains('Bolsa de plastico')]\n",
    "    data = data[~ data['NOMBRE_PRODUCTO'].str.contains('Palets')]\n",
    "    data = data[~ data['NOMBRE_PRODUCTO'].str.contains('DESCUENTO')]\n",
    "    data = data[~ data['NOMBRE_PRODUCTO'].str.contains('Bolsas Termicas')]\n",
    "    data = data[~ data['NOMBRE_PRODUCTO'].str.contains('Insumo de cafeteria')]\n",
    "    data = data[data['ID_PRODUCTO'] != '00000000']\n",
    "    data = data[data['NOMBRE_PRODUCTO'] != 'a']\n",
    "    data.drop(data.tail(1).index, inplace=True)\n",
    "    data.drop(['Total Euros IVA'], axis = 1 , inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    #ORGANIZAMOS LAS CATEGORIAS PORQUE ALGUNAS SE REPITEN\n",
    "    mapeo_categorias = {\n",
    "    'Pepinos': 'Frutas y Verduras',\n",
    "    'Tomates': 'Frutas y Verduras',\n",
    "    'Setas': 'Frutas y Verduras',\n",
    "    'Cerveza': 'Bebidas alcoholicas',\n",
    "    'VINO': 'Bebidas alcoholicas',\n",
    "    'Vodka': 'Bebidas alcoholicas',\n",
    "    'Brandy': 'Bebidas alcoholicas',\n",
    "    'salsa': 'Salsa',\n",
    "    'Barquillos' : 'Dulces',\n",
    "    'Bizcochos' : 'Dulces',  \n",
    "    'Galletas' : 'Dulces',\n",
    "    'Bombones' : 'Dulces', \n",
    "    'Tartas' : 'Dulces', \n",
    "    'Te,Café' : 'Te,Cafe',\n",
    "    'Zumo' : 'Agua y refrescos', \n",
    "    'Productos Lacteos Congelados' : 'Productos lacteos', \n",
    "    'Salchichon RO' : 'Salchichon i embutidos', \n",
    "      }\n",
    "    data['CATEGORIA'] = data['CATEGORIA'].replace(mapeo_categorias)\n",
    "    data['ID_PRODUCTO'] =data['ID_PRODUCTO'].fillna('00010901')\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b0459-4ce3-4453-8b0d-cbe842c37128",
   "metadata": {},
   "source": [
    "## DATAFRAMES LIMPIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b1a2ef-aa64-401a-a99c-a8285ff64408",
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas = limpieza(data)\n",
    "info_productos = limpieza2(productos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bec6f9-746f-4eb0-97a9-f16224f1a59a",
   "metadata": {},
   "source": [
    "## DATOS UNIDOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a66bd8-e730-4e31-8bdc-e8cef900eceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAMOS A UNIR LOS DOS DATAFRAMES EN SOLO UNO POR LA COLUMNA COMUN ID_PRODUCTO\n",
    "tienda = pd.merge(ventas, info_productos, on='ID_PRODUCTO', how='inner')\n",
    "tienda.drop(['NOMBRE_PRODUCTO_y', 'PROVEEDOR', 'UNIDADES_VENDIDAS', 'PRECIO_UNIDAD', 'CANAL_VENTA',], axis=1, inplace=True)\n",
    "tienda.rename(columns={'NOMBRE_PRODUCTO_x': 'NOMBRE_PRODUCTO', 'CADUCIDAD_2': 'CADUCIDAD'}, inplace=True)\n",
    "tienda.drop('NOMBRE_PRODUCTO', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a150f5ab-c055-4f52-9501-cd46878c2e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tienda.to_csv('tienda.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db1d540-7af5-4809-85c1-325a80bf43c8",
   "metadata": {},
   "source": [
    "# CONCLUSIÓN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deae47f1-b478-4a27-a129-75646a28d0bc",
   "metadata": {},
   "source": [
    "La información proporcionada por la empresa ha sido extremadamente valiosa, ya que nos brindó la oportunidad de trabajar con datos reales. Sin embargo, nos enfrentamos a dataframes bastante desordenados, lo que requirió un extenso proceso de limpieza. A lo largo de nuestro trabajo, hemos tenido que regresar varias veces para incorporar nuevos elementos de limpieza a medida que descubríamos más desafíos en los datos.\n",
    "Durante este proceso, hemos llegado a comprender la importancia crítica de la limpieza de datos. Su impacto directo en la calidad, confiabilidad y utilidad de la información no puede subestimarse. Los conjuntos de datos limpios no solo facilitan una manipulación más eficiente, sino que también posibilitan una extracción de información más rápida y precisa.\n",
    "La observación de que trabajar con datos limpios reduce significativamente la necesidad de corregir errores o abordar problemas de calidad durante las etapas posteriores del análisis es crucial. Esto no solo mejora la eficiencia operativa, sino que también asegura la precisión de los resultados analíticos, fundamentales para la toma de decisiones informada.\n",
    "En resumen, la limpieza de datos se revela como un componente esencial en este proceso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
